import copy
## GSP
# implementation of the generalized sequential pattern mining (GSP) algorithm for mining frequent patterns from discrete sequences

# def get_sequences_from_file(file_path):
#     sequences = []
#     with open(file_path, 'r') as file:
#         for line in file:
#             timestamp, sequence = line.strip().split()[0], line.strip().split()[1:]
#             sequences.append(sequence)
#     return sequences

def get_sequences_from_file(file_path):
    sequences = []
    with open(file_path, 'r') as file:
        for line in file:
            _, sequence = line.strip().split()[0], line.strip().split()[1:]
            sequences.append(sequence[0])
    return sequences



def join_sequences(frequent_items, maxspan, maxgap):
    # candidate (k + 1)-sequences are generated by combining pairs of frequent k-sequences
    candidates = []

    # Fix a canonical order on the sequences and ensure that each candidate (k + 1)-subsequence is generated by only one pair of k-sequences ??

    # Test for check_candidate_gen
    # print(check_candidate_gen(['CW','R'],['W','CR']))
    # print(check_candidate_gen(['W','RW'],['CRW']))
    # print(check_candidate_gen(['CW','R'],['W','R','S']))
    # print(check_candidate_gen(['W','CR','S'],['CR','S','S']))
    
    for i in range(len(frequent_items)):
        Sa = frequent_items[i]
 
        for j in range(len(frequent_items)):

            Sb = frequent_items[j]

            Sc = []

            if check_candidate_gen(Sa,Sb) != 0:
                
                if isinstance(Sa,str) and isinstance(Sb,str):
                    Sc.append(Sa)
                    Sc.append(Sb)
                    candidates.append(Sc)
                
                # If the first itemset of Sa is a singleton, Sc is generated by prepending it to Sb
                elif len(Sa[0])==1: # here I'm checking if the first element of Sa is a singleton
                    # Sa = "".join(Sa)
                    # Sb = "".join(Sb)
                    if isinstance(Sa,list): 
                        Sc.extend(Sa)
                    else:
                        Sc.append(Sa)
                    #Sc.append(Sb)
                    #Sc = "".join(Sc)
                    # If the element is a list, extend the transformed_list with its elements
                    if isinstance(Sb, list):
                        Sc.extend(Sb)
                    else:
                        Sc.append(Sb)
                    candidates.append(Sc)
                    
                # If the first itemset of Sa is not a singleton, Sc is generated by replacing the first itemset of Sb with it
                elif len(Sa[0])>1:
                    # Sa = "".join(Sa)
                    # Sb = "".join(Sb)
                    Sc.extend(Sa)
                    if isinstance(Sb, list):
                        Sc.extend(Sb[1:])
                        # otherwise Sb is a singleton so it'll be replaced by Sa
                    # Sc = "".join(Sc)
                    candidates.append(Sc)

                # If the last itemset of Sb is a singleton, Sc is generated by appending it to Sa
                elif len(list(Sb)[-1])==1:
                    # Sa = "".join(Sa)
                    # Sb = "".join(Sb)
                    Sc.extend(Sa)
                    Sc.append(Sb[-1])
                    # Sc = "".join(Sc)
                    candidates.append(Sc)

                # If the last itemset of Sb is not a singleton, Sc is generated by replacing the last itemset of Sa with it
                elif len(list(Sb)[-1])>1:
                    # Sa = "".join(Sa)
                    # Sb = "".join(Sb)
                    Sc.extend(Sa[0:(len(Sa)-2)])
                    Sc.append(Sb[-1])
                    # Sc = "".join(Sc)
                    candidates.append(Sc)
    
    return candidates

def check(Sa,Sb): # check whether the difference between the itemset from Sa and the corresponding itemset in Sb consists
    # of just one item.
    return len(Sa)==len(Sb)

def check_candidate_gen(Sa, Sb): 
    # removing an item from the first itemset of Sa and removing an item from the 
    # last itemset of Sb should result in the same sequence So
   
    if len(Sa[0])==1:
        Sa = Sa[1:]  # If the itemset is a singleton, the entire itemset is deleted for the test:
        if len(Sb[-1])==1: # Sa[0] is a singleton, Sb[-1] is a singleton
            Sb = Sb[0:len(Sb)-1]
            return check(Sa,Sb)
        else: # Sa[0] is a singleton, Sb[-1] is not
            Sb[-1] = Sb[-1][1:]
            return check(Sa,Sb)
    else: 
        Sa[0] = Sa[0][1:]
        if len(Sb[-1])==1: # Sa[0] is not a singleton, Sb[-1] is a singleton
            Sb = Sb[0:len(Sb)-1]
            return check(Sa,Sb)
        else: # Sa[0] is not a singleton, Sb[-1] is not a singleton
            return check(Sa,Sb)
        
# def is_contained(candidate, itemset): # check if the candidate is contained in the itemset
#     # example: if ['C'] is contained in ['CW']
#     candidate_set = set(list(candidate[0]))
#     itemset_set = set(list(itemset[0]))
#     return candidate_set.issubset(itemset_set)

def find(dataset,candidate,max_gap): # find the sequence in the dataset
    flag = [0]*len(candidate)
    gap = 0
    for i in range(1,len(dataset)): # the first element is the first candidate that we already identified
        for j in range(len(candidate)):
            if candidate[j] == dataset[i] and gap < max_gap:
                flag[j] = 1
                if all(element != 0 for element in flag):
                    return 1
                else:
                    gap = 0
        gap += 1
    return all(element != 0 for element in flag)

def is_subsequence(candidate, dataset, max_span, max_gap):

    # CONSTRAINTS
    # 1. maximum span limit the time difference between the first and last itemsets of a subsequence
    # 2. maximum gap limit the number of gaps between successive itemsets of a subsequence

    # amount = [0]*len(candidate) # this counts how many itemsets of the candidate are present in the dataset

    # for j in range(len(candidate)):
    #     for i in range(len(dataset)):
    #         if is_contained(candidate[j], dataset[i]):
    #             amount[j] += 1
    # now amount is an array of 0 and 1, if we have all 1 (like [1 1 1]) then all the itemsets of the candidate are in the dataset
    # this check is not strictly necessary and increases the computational time but makes easier the following part

    # maybe we can try without checking if all the itemsets of the candidate are present in the dataset at least once  
    # let's directly count how many occurrences we have
        
        k = 0 # k counts how many times the sequence of candidates appears in the dataset

        while dataset != []:

            # search the first occurrence of candidate[0]
            for i in range(len(dataset)):
                if candidate[0]==dataset[i]:
                    dataset = dataset[i:] # cut the dataset: the first element is now the itemset == candidate[0]
                    break

            # now the first element of the dataset is the first occurrence 
            if len(candidate)==1:
                k += 1
            else:
                k += find(dataset[:max_span],candidate[1:],max_gap)
                # returns 1 if it founds all the other candidates in the dataset (considering the max_span)
            
            dataset = dataset[i+1:] # proceed in the search 

        return k
    #         while j < len(candidate):

    #             if k==0: # first occurence of candidate[0]
    #                 last_i = i
    #                 k = 1
    #                 span_start = i
    #             else:
    #                 k += 1
    #     else:
    #         return 0 # in this case the candidate is not a subsequence of the dataset


    # # Iterate through both lists
    # while i < len(candidate) and j < len(dataset):
    #     # If the elements match, move to the next element in both lists
    #     if is_contained(candidate[i], dataset[j]) and abs(i-j) < max_gap:
    #         k += 1
    #         if span_start is None:
    #             span_start = j  # Start of the span
    #         i += 1
    #     # Move to the next element in the dataset
    #     j += 1
    
    # # If all elements of the candidate list are found in the sequence in the same order, check constraints
    # if i == len(candidate):
    #     span_end = j - 1  # End of the span
    #     span_length = span_end - span_start

    #     # Check constraints
    #     if span_length <= max_span:
    #         return k
    
    # return 0

def count_support(dataset, candidates, maxspan, maxgap):

    dic = {}
    # the support of subsequence S in sequence D is the number of occurrences of S in D

    for candidate in candidates:
        k = is_subsequence(candidate, dataset, maxspan, maxgap)
        if k:
            # itemset = "".join(itemset[0])
            key = '-'.join(candidate)
            dic[key] = {'subsequence': candidate, 'support' : k}


    return dic

def count_frequent_items(dataset):
    # count support of items.... or itemsets?
    # for sequence in dataset:
    #     for itemset in sequence:
    #         for i in itemset:
    #             if i in item_counts:
    #                 item_counts[i] += 1
    #             else:
    #                 item_counts[i] = 1

    # itemsets:
    item_counts = {}
    result = {}
    for itemset in dataset:
        if itemset in item_counts:
            item_counts[itemset] += 1
        else:
            item_counts[itemset] = 1
    
    for item in item_counts:
        if item_counts[item] >= minsup:
            result.update({item: {'subsequence': item, 'support': item_counts[item]}})
     # item: count for item, count in item_counts.items() if count >= minsup}

    return result

def gsp(dataset, minsup, maxspan, maxgap):
    k = 1

    # Fk: all frequent itemset
    frequent_items = count_frequent_items(dataset)

    result = {}

    # while Fk != 0
    while k<3: #len(frequent_items)!=0 :

        # generate C_k+1 by joining pairs of sequences from F_k
        subsequences = [value['subsequence'] for value in frequent_items.values()]
        candidates = join_sequences(subsequences, maxspan, maxgap)
        candidate_support = count_support(dataset, candidates, maxspan, maxgap)

        # S in C_k+1
        for key, value in candidate_support.items():
            if value['support'] >= minsup:
                frequent_items[key] = value # add to result if the support is > minsup
        result.update(frequent_items) # F_k+1

        k += 1

    return result # dict object made of 'subsequence' and 'support'

## Apply the algorithm on the CRSW dataset:
# `2019-01-03_itemsets-CRSW.txt` Two months worth of weather in Kuopio (January–February 2019), obtained from https://en.ilmatieteenlaitos.fi/download-observations#!/
# Each line represents weather events during one hour as an itemset. The first column contains the contextual attribute, i.e. indication of time in Year-Month-Day_Hour format.
# The second column contains the itemset. C, R S and W stand respectively for clouds, precipitation, sunshine and wind.

file_path = "2019-01-03_itemsets-CRSW.txt" 
minsup = 150
maxspan = 100
maxgap = 5
dataset = get_sequences_from_file(file_path)
result = gsp(dataset, minsup, maxspan, maxgap)

# Print the frequent patterns
print(f"Minimum support threshold = {minsup}")
print(f"Maximum span = {maxspan}")
print(f"Maximum gap = {maxgap}")
print("Frequent patterns:")
for key in result:
    print(f"Sequence: {result[key]['subsequence']}, Support: {result[key]['support']}")

# Try diff erent values for the mininum support threshold, diff erent constraints such as max gap and max span,
# and considering the data either as one long sequence or with each day as a separate short sequence. You might
# also try replacing repeated occurrences of the same itemset by a single copy, i.e. represent constant weather
# during successive hours with only one itemset.
# Report on the type and number of patt erns obtained under diff erent conditions.
